ssh emmettt@ssh.swc.ucl.ac.uk -o "ServerAliveInterval 180"

ssh hpc-gw1

module load miniconda 

conda activate replay 

cd code/Replay


####la
to generate prepared data files:

on local machine in open jupyter notebook 'prepare_data'. 

This will create txt and json files for eahc animal that is to be run

####
for runing multiple animals
prep a slurm file, tha has the appropriate number of arrays (1 for each animal) 
make sure the corresponding .jl file has a list of each animal to be run also   

push the reop with sourcetree and pull again on the cluster:

git checkout . 
git pull origin emmett

cd into PPSeq.jl directory
git branch
(git checkout .    - to update it)
(make sure you are on the sacred seqs branch and all is up to date) 

(will ask for username: EmmettJT and password - this is a key that github makes 
at the moment it is as follows (but it will expire)

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

then run the slurm file 
sbatch xxxxx.slurm


to run a single instance


srun -p cpu -t 2-22:00 -c 10 --pty --mem=30G bash

julia PPSeq_all_animals_emmett.jl --data-directory "/nfs/winstor/sjones/projects/sequence_squad/organised_data/ppseq_data/prepared_data/ppseq_ready/" --num-threads 10 --results-directory "/nfs/winstor/sjones/projects/sequence_squad/organised_data/ppseq_data/awake/" --results-name testing_code --slurm-array-task-id 10


sleep:

julia PPSeq_all_animals_emmett.jl --data-directory "/nfs/winstor/sjones/projects/sequence_squad/organised_data/ppseq_data/prepared_data/ppseq_ready/" --num-threads 10 --results-directory "/nfs/winstor/sjones/projects/sequence_squad/organised_data/ppseq_data/sleep/" --results-name testing_code --slurm-array-task-id 13 --sacred-directory "/nfs/winstor/sjones/projects/sequence_squad/organised_data/ppseq_data/awake/" --sacred-data-file "test_data"





