{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1286b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_ephys.analysis import Session\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def AlignToTriggersAndFIndEphysTimestamps(Port_intimes,trial_id,first_poke_times,trial_start,TrialStart_EphysTime,FirstPoke_EphysTime):\n",
    "\n",
    "    new_TS = []\n",
    "    for index, trial in enumerate(trial_id):\n",
    "        if np.isnan(Port_intimes[index]):\n",
    "            new_TS = new_TS + [np.nan]\n",
    "        else:\n",
    "\n",
    "            current_poke_event_time = Port_intimes[index]\n",
    "\n",
    "            # find ech relevant timestamps\n",
    "            CurrentTrial_startTS = trial_start[trial-1]\n",
    "            First_pokeTS = first_poke_times[trial-1]\n",
    "\n",
    "            # last trial has no next trial start\n",
    "            if trial == trial_id[-1]:\n",
    "                NextTrial_startTS = 9999999999999\n",
    "            else:\n",
    "                NextTrial_startTS = np.unique(trial_start)[trial]\n",
    "\n",
    "            trialstart_diff =  abs(CurrentTrial_startTS - current_poke_event_time)\n",
    "\n",
    "            EphysTS = TrialStart_EphysTime[trial-1]\n",
    "            current_dist = current_poke_event_time - CurrentTrial_startTS \n",
    "            distance = EphysTS + current_dist\n",
    "\n",
    "            new_TS = new_TS + [distance]\n",
    "            \n",
    "    return(new_TS)\n",
    "\n",
    "\n",
    "def align_open_ephys_processors(main_processor_tuple, aux_processor_tuples, session_path=None, synch_channel=1):\n",
    "\n",
    "    session_data = Session(str(session_path))\n",
    "    if len(session_data.recordnodes) != 1:\n",
    "        raise ValueError(\"should be exactly one record node.\")\n",
    "    if len(session_data.recordnodes[0].recordings) != 1:\n",
    "        raise ValueError(\"Should be exactly one recording.\")\n",
    "        \n",
    "    for rn, recordnode in enumerate(session_data.recordnodes):\n",
    "        for r, recording in enumerate(recordnode.recordings):\n",
    "            # Synch\n",
    "            recording.add_sync_line(\n",
    "                synch_channel,\n",
    "                main_processor_tuple[0],\n",
    "                main_processor_tuple[1],\n",
    "                main=True,\n",
    "            )\n",
    "            for aux_processor in aux_processor_tuples:\n",
    "                recording.add_sync_line(\n",
    "                    synch_channel,\n",
    "                    aux_processor[0],\n",
    "                    aux_processor[1],\n",
    "                    main=False,\n",
    "                )\n",
    "            print('this should be zero:')\n",
    "            print(rn)\n",
    "        \n",
    "    return recording\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca5ae8",
   "metadata": {},
   "source": [
    "set paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea374d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "DATES should line up:\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\EJT178_implant1\\recording7_30_03_2022\n",
      "Z:\\projects\\sequence_squad\\data\\raw_neuropixel\\OE_DATA\\EJT178\\300322\\2022-03-30_13-48-39\\\\\n",
      "Z:\\projects\\sequence_squad\\data\\raw_neuropixel\\OE_DATA\\EJT178\\300322\\2022-03-30_13-48-39\\Record Node 103\\experiment1\\recording1\\continuous\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## set paths!\n",
    "\n",
    "mouse_implant_recording = '178_1_7'\n",
    "\n",
    "\n",
    "OE_processor_path = r\"Z:\\projects\\sequence_squad\\data\\raw_neuropixel\\OE_DATA\\EJT178\\300322\\2022-03-30_13-48-39\\Record Node 103\\experiment1\\recording1\\continuous\"\n",
    "OE_raw_path = r\"Z:\\projects\\sequence_squad\\data\\raw_neuropixel\\OE_DATA\\EJT178\\300322\\2022-03-30_13-48-39\\\\\"\n",
    "\n",
    "# this is the path to a histology file, this is needed in order to know the exact depth/location of each electrode\n",
    "hist_path = r\"Z:\\projects\\sequence_squad\\data\\histology\\Neuropixel_tracks\\EJT178_neuropixel\\brainreg\\manual_segmentation\\standard_space\\tracks\\\\\"  \n",
    "hist_file = 'implant1'\n",
    "\n",
    "\n",
    "##### check date at bottom lines up:\n",
    "PATH = r\"Z:\\projects\\sequence_squad\\organised_data\\animals\"\n",
    "\n",
    "for file_ in os.listdir(PATH):\n",
    "    if 'EJT' in file_.split('_')[0]:\n",
    "        mouse_number = int(re.findall(r'\\d+', file_.split('_')[0])[0])\n",
    "        implant_number = int(re.findall(r'\\d+', file_.split('_')[-1])[0])\n",
    "        if mouse_implant_recording.split('_')[0] == str(mouse_number):\n",
    "            if mouse_implant_recording.split('_')[1] == str(implant_number):\n",
    "                mouse_name = file_.split('_')[0]\n",
    "                implant_num = implant_number\n",
    "                PATH = os.path.join(PATH,file_)\n",
    "                break\n",
    "for file_ in os.listdir(PATH):\n",
    "    if 'recording' in file_.split('_')[0]:\n",
    "        if mouse_implant_recording.split('_')[-1] == str(re.findall(r'\\d+', file_.split('_')[0])[0]):\n",
    "            date_file = file_\n",
    "            org_data_path = os.path.join(PATH,date_file)\n",
    "            break\n",
    "            \n",
    "print('---------------------------------------------------')\n",
    "print('DATES should line up:')\n",
    "print(org_data_path)\n",
    "print(OE_raw_path)\n",
    "print(OE_processor_path)\n",
    "print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa9d6e",
   "metadata": {},
   "source": [
    "set processor variables to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f41758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample rate:\n",
    "Fs = 2500\n",
    "\n",
    "## import NP track position:\n",
    "import pandas as pd\n",
    "\n",
    "probe_track_file = hist_path + hist_file + '.csv'\n",
    "\n",
    "implant_df = pd.read_csv(probe_track_file)\n",
    "\n",
    "import re\n",
    "count = 0\n",
    "for processor in os.listdir(OE_processor_path):\n",
    "    if count == 0:\n",
    "        main1 = int(re.findall(r'\\d+', processor)[0])\n",
    "        main1_2 = processor.split('.')[-1]\n",
    "    elif count == 1:\n",
    "        main2 = int(re.findall(r'\\d+', processor)[0])\n",
    "        main2_2 = processor.split('.')[-1]\n",
    "    elif count == 2:\n",
    "        main3 = int(re.findall(r'\\d+', processor)[0])\n",
    "        main3_2 = processor.split('.')[-1]\n",
    "    count +=1 \n",
    "\n",
    "main_processor_tuple=(main1, main1_2)\n",
    "\n",
    "aux_processor_tuples=((main2,main2_2),(main3,main3_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3542507f",
   "metadata": {},
   "source": [
    "load in OE data and align across processors (global alignment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25aa2338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this should be zero:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### LOAD in data: this could take a few minutes\n",
    "recording = align_open_ephys_processors(main_processor_tuple,aux_processor_tuples,OE_raw_path)\n",
    "recording.compute_global_timestamps()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5246f52",
   "metadata": {},
   "source": [
    "align to depth information and to offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a408955",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = recording.continuous[1].samples\n",
    "\n",
    "if int(mouse_implant_recording.split('_')[0]) > 250:\n",
    "    timestamps = recording.continuous[1].timestamps\n",
    "else:\n",
    "    timestamps = np.load(OE_processor_path + '\\\\' + 'Neuropix-PXI-' + str(aux_processor_tuples[0][0]) + '.' + str(aux_processor_tuples[0][1]) + '\\\\' + 'synchronized_timestamps.npy')\n",
    "\n",
    "## chose 6 channels: #\n",
    "channels = [50,100,150,200,250,300,350]\n",
    "\n",
    "### add in region info based on depth:\n",
    "try:\n",
    "    callosum_middle_index = int(np.median(np.where(implant_df['Region acronym'].values == 'ccb')))\n",
    "except:\n",
    "    callosum_middle_index = int(np.median(np.where(implant_df['Region acronym'].values == 'ccg')))\n",
    "\n",
    "proportion_in_motor_cortex = (callosum_middle_index/len(implant_df))\n",
    "# there should be 400 channels per 4000um \n",
    "# tot_channels = 384\n",
    "# bank_spacing = 20 # 20um\n",
    "# channels_per_bank = 2\n",
    "first_cortex_channel = int(proportion_in_motor_cortex * 400)\n",
    "\n",
    "# save out data:\n",
    "timestamps_s = timestamps/2500\n",
    "timestamps_s_offset_adjusted = timestamps_s - timestamps_s[0]\n",
    "\n",
    "channel_regions = []\n",
    "for channel in channels:\n",
    "    if channel > first_cortex_channel:\n",
    "        channel_regions.append('m_crtex')\n",
    "    elif channel < first_cortex_channel:\n",
    "        channel_regions.append('striatum')\n",
    "\n",
    "# save timestamp data\n",
    "save_file_path = org_data_path + r\"/ephys/LFP/\"\n",
    "if not os.path.isdir(save_file_path):\n",
    "    os.makedirs(save_file_path)\n",
    "    \n",
    "np.save(save_file_path+ 'LFP_timestamps.npy',timestamps_s)\n",
    "np.save(save_file_path+ 'aligned_LFP_timestamps.npy',timestamps_s_offset_adjusted)\n",
    "\n",
    "## free up memory\n",
    "del timestamps_s\n",
    "del timestamps_s_offset_adjusted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd00e574",
   "metadata": {},
   "source": [
    "loop over each chosen channel and save out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72b02ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                           | 0/18796 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved for channel 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                           | 0/18796 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved for channel 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                           | 0/18796 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved for channel 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                           | 0/18796 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved for channel 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                           | 0/18796 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved for channel 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                           | 0/18796 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved for channel 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                           | 0/18796 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved for channel 350\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "### add in region info based on depth:\n",
    "for chosen_channel in channels:\n",
    "    data_channel = []\n",
    "    chunk_size = 2000 # adjust this value to balance speed and memory usage\n",
    "    for i in tqdm(range(0, len(data), chunk_size)):\n",
    "        chunk = [data[j][chosen_channel] for j in range(i, min(i+chunk_size, len(data)))]\n",
    "        data_channel += chunk\n",
    "        \n",
    "    if chosen_channel > first_cortex_channel:\n",
    "        data_region = 'm-crtx'\n",
    "    elif chosen_channel < first_cortex_channel:\n",
    "        data_region = 'striatum'\n",
    "        \n",
    "    save_path = save_file_path + 'channel-' + str(chosen_channel) + '_REGION-' + data_region + \"_LFP_data.npy\"\n",
    "    \n",
    "    np.save(save_path,data_channel)\n",
    "    print('data saved for channel ' + str(chosen_channel))\n",
    "    # clean up for memory\n",
    "    del data_channel\n",
    "    \n",
    "print('done')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28166b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
